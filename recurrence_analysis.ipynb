{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a833e42",
   "metadata": {},
   "source": [
    "# Recurring Transfers Analysis (Daily / Weekly / Monthly)\n",
    "This notebook loads a `transactions` file (CSV or Excel), computes daily/weekly/monthly recurrence for each `(AccountNumber, CorrespondentAccountNumber)` pair over the dataset timeframe, **filters pairs that have 100% recurrence**, and generates six visualizations:\n",
    "\n",
    "1. Calendar-style heatmap (per pair)  \n",
    "2. Timeline/line plot of transfer presence or counts  \n",
    "3. Heatmap (pairs × days/weeks)  \n",
    "4. Network graph of recurring pairs  \n",
    "5. Bar chart of top recurring pairs  \n",
    "6. Amount-based recurrence / stability check\n",
    "\n",
    "**How to use**:  \n",
    "- Place your `transactions.csv` or `transactions.xlsx` in the same directory as this notebook before running.  \n",
    "- The notebook expects columns: `AccountNumber`, `CorrespondentAccountNumber`, `ValueDate` (case-insensitive). If your column names differ, adapt the `rename` mapping in the \"Load & normalize\" cell.\n",
    "\n",
    "Files created by the notebook:\n",
    "- `/mnt/data/recurrence_results.xlsx` — summary tables of recurring pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and data (tries CSV then Excel)\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Try common filenames\n",
    "candidates = ['transactions.csv', 'transactions.xlsx', 'transactions.xls']\n",
    "found = None\n",
    "for fn in candidates:\n",
    "    if os.path.exists(fn):\n",
    "        found = fn\n",
    "        break\n",
    "\n",
    "if found is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No transactions file found. Please upload 'transactions.csv' or 'transactions.xlsx' into the notebook working directory.\"\n",
    "    )\n",
    "\n",
    "print(f\"Loading file: {found}\")\n",
    "if found.lower().endswith('.csv'):\n",
    "    df = pd.read_csv(found, parse_dates=['ValueDate'] if 'ValueDate' in pd.read_csv(found, nrows=0).columns else None)\n",
    "else:\n",
    "    df = pd.read_excel(found, parse_dates=['ValueDate'] if 'ValueDate' in pd.read_excel(found, nrows=0).columns else None)\n",
    "\n",
    "# normalize column names (case-insensitive)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "col_map = {}\n",
    "for c in df.columns:\n",
    "    lc = c.lower()\n",
    "    if lc in ('accountnumber','account','from_account','fromacct'):\n",
    "        col_map[c] = 'AccountNumber'\n",
    "    if lc in ('correspondentaccountnumber','corr_account','to_account','toacct','correspondent'):\n",
    "        col_map[c] = 'CorrespondentAccountNumber'\n",
    "    if lc in ('valuedate','value_date','value','date','ts','timestamp'):\n",
    "        col_map[c] = 'ValueDate'\n",
    "    if lc in ('amount','amt','transactionamount'):\n",
    "        col_map[c] = 'Amount'\n",
    "\n",
    "df = df.rename(columns=col_map)\n",
    "required = ['AccountNumber','CorrespondentAccountNumber','ValueDate']\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}. Please rename your columns to include AccountNumber, CorrespondentAccountNumber, and ValueDate.\")\n",
    "\n",
    "# Ensure ValueDate is datetime\n",
    "df['ValueDate'] = pd.to_datetime(df['ValueDate'])\n",
    "\n",
    "# create bucket columns\n",
    "df['date'] = df['ValueDate'].dt.date\n",
    "df['week'] = df['ValueDate'].dt.to_period('W').apply(lambda r: r.start_time.date())\n",
    "df['month'] = df['ValueDate'].dt.to_period('M').apply(lambda r: r.start_time.date())\n",
    "\n",
    "print('Data loaded. Rows:', len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ad4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute total buckets and counts per pair\n",
    "total_days = df['date'].nunique()\n",
    "total_weeks = df['week'].nunique()\n",
    "total_months = df['month'].nunique()\n",
    "\n",
    "print('Total days:', total_days, 'Total weeks:', total_weeks, 'Total months:', total_months)\n",
    "\n",
    "daily_counts = df.groupby(['AccountNumber','CorrespondentAccountNumber'])['date'].nunique().reset_index(name='days_with_transfer')\n",
    "weekly_counts = df.groupby(['AccountNumber','CorrespondentAccountNumber'])['week'].nunique().reset_index(name='weeks_with_transfer')\n",
    "monthly_counts = df.groupby(['AccountNumber','CorrespondentAccountNumber'])['month'].nunique().reset_index(name='months_with_transfer')\n",
    "\n",
    "final_df = daily_counts.merge(weekly_counts, on=['AccountNumber','CorrespondentAccountNumber'], how='outer') \\\n",
    "    .merge(monthly_counts, on=['AccountNumber','CorrespondentAccountNumber'], how='outer')\n",
    "\n",
    "final_df[['days_with_transfer','weeks_with_transfer','months_with_transfer']] = final_df[['days_with_transfer','weeks_with_transfer','months_with_transfer']].fillna(0).astype(int)\n",
    "\n",
    "final_df['total_days'] = total_days\n",
    "final_df['total_weeks'] = total_weeks\n",
    "final_df['total_months'] = total_months\n",
    "\n",
    "final_df['pct_daily'] = final_df['days_with_transfer'] / total_days * 100\n",
    "final_df['pct_weekly'] = final_df['weeks_with_transfer'] / total_weeks * 100\n",
    "final_df['pct_monthly'] = final_df['months_with_transfer'] / total_months * 100\n",
    "\n",
    "# Save full summary\n",
    "final_df_sorted = final_df.sort_values(['pct_weekly','pct_daily','pct_monthly'], ascending=False)\n",
    "final_df_sorted.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter pairs with 100% recurrence in any of daily/weekly/monthly\n",
    "daily_100 = final_df[(final_df['pct_daily'] == 100)].copy().reset_index(drop=True)\n",
    "weekly_100 = final_df[(final_df['pct_weekly'] == 100)].copy().reset_index(drop=True)\n",
    "monthly_100 = final_df[(final_df['pct_monthly'] == 100)].copy().reset_index(drop=True)\n",
    "\n",
    "print('Pairs with 100% daily recurrence:', len(daily_100))\n",
    "print('Pairs with 100% weekly recurrence:', len(weekly_100))\n",
    "print('Pairs with 100% monthly recurrence:', len(monthly_100))\n",
    "\n",
    "# Save results to Excel for easy download\n",
    "output_path = '/mnt/data/recurrence_results.xlsx'\n",
    "with pd.ExcelWriter(output_path) as xw:\n",
    "    final_df_sorted.to_excel(xw, sheet_name='all_pairs', index=False)\n",
    "    daily_100.to_excel(xw, sheet_name='daily_100', index=False)\n",
    "    weekly_100.to_excel(xw, sheet_name='weekly_100', index=False)\n",
    "    monthly_100.to_excel(xw, sheet_name='monthly_100', index=False)\n",
    "\n",
    "print('Saved results to', output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687022a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "# We'll generate visualizations for pairs with 100% recurrence.\n",
    "# To avoid excessive plots, cap the number visualized per recurrence type to N (default 20).\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from textwrap import wrap\n",
    "try:\n",
    "    import networkx as nx\n",
    "    nx_available = True\n",
    "except Exception:\n",
    "    nx_available = False\n",
    "\n",
    "VISUAL_CAP = 20\n",
    "\n",
    "def pairs_from_df(df_pairs, cap=VISUAL_CAP):\n",
    "    pairs = list(zip(df_pairs['AccountNumber'].astype(str), df_pairs['CorrespondentAccountNumber'].astype(str)))\n",
    "    return pairs[:cap]\n",
    "\n",
    "daily_pairs = pairs_from_df(daily_100)\n",
    "weekly_pairs = pairs_from_df(weekly_100)\n",
    "monthly_pairs = pairs_from_df(monthly_100)\n",
    "\n",
    "print('Will visualize up to', VISUAL_CAP, 'pairs per recurrence bucket (if available).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33106a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Calendar-style heatmap per pair (daily presence)\n",
    "# For each pair, create a simple heatline plot showing presence across the date range.\n",
    "def plot_calendar_heatline(pair, df, ax=None):\n",
    "    a, b = pair\n",
    "    mask = (df['AccountNumber'].astype(str) == str(a)) & (df['CorrespondentAccountNumber'].astype(str) == str(b))\n",
    "    s = df[mask].copy()\n",
    "    if s.empty:\n",
    "        return None\n",
    "    idx = pd.date_range(df['ValueDate'].min().date(), df['ValueDate'].max().date(), freq='D')\n",
    "    presence = s.groupby(s['ValueDate'].dt.date).size().reindex(idx.date, fill_value=0)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12,1.5))\n",
    "    ax.plot(idx, (presence>0).astype(int), linewidth=1)\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    ax.set_yticks([0,1])\n",
    "    ax.set_yticklabels(['no','yes'])\n",
    "    ax.set_title(f'Presence by day for pair {a} -> {b}')\n",
    "    ax.set_xlabel('Date')\n",
    "    return ax\n",
    "\n",
    "# Example: create a multi-plot figure for first few daily pairs\n",
    "n = len(daily_pairs)\n",
    "if n>0:\n",
    "    cols = 1\n",
    "    rows = n\n",
    "    fig = plt.figure(figsize=(12, 1.5*rows))\n",
    "    for i, pair in enumerate(daily_pairs, start=1):\n",
    "        ax = fig.add_subplot(rows, cols, i)\n",
    "        plot_calendar_heatline(pair, df, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No 100% daily pairs to visualize.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Timeline/line plot (daily counts or presence) for a selected pair list (weekly and monthly similarly)\n",
    "def plot_time_series(pair, df, freq='D', ax=None):\n",
    "    a,b = pair\n",
    "    mask = (df['AccountNumber'].astype(str) == str(a)) & (df['CorrespondentAccountNumber'].astype(str) == str(b))\n",
    "    s = df[mask].copy()\n",
    "    if s.empty:\n",
    "        return None\n",
    "    s = s.set_index('ValueDate').sort_index()\n",
    "    if freq=='D':\n",
    "        ts = s['AccountNumber'].resample('D').count()\n",
    "    elif freq=='W':\n",
    "        ts = s['AccountNumber'].resample('W').count()\n",
    "    elif freq=='M':\n",
    "        ts = s['AccountNumber'].resample('M').count()\n",
    "    else:\n",
    "        raise ValueError('freq must be D/W/M')\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12,3))\n",
    "    ax.plot(ts.index, ts.values)\n",
    "    ax.set_title(f'Transfer counts over time for {a} -> {b} (freq={freq})')\n",
    "    ax.set_ylabel('count')\n",
    "    return ax\n",
    "\n",
    "# Plot for top N weekly pairs (if exist)\n",
    "if weekly_pairs:\n",
    "    n = len(weekly_pairs)\n",
    "    fig = plt.figure(figsize=(12,3*n))\n",
    "    for i, pair in enumerate(weekly_pairs, start=1):\n",
    "        ax = fig.add_subplot(n,1,i)\n",
    "        plot_time_series(pair, df, freq='W', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No 100% weekly pairs to visualize.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Heatmap per pair vs day (binary presence)\n",
    "# Build a matrix for up to VISUAL_CAP pairs (rows) and all dates (cols)\n",
    "def build_presence_matrix(pairs, df):\n",
    "    dates = pd.date_range(df['ValueDate'].min().date(), df['ValueDate'].max().date(), freq='D')\n",
    "    mat = []\n",
    "    labels = []\n",
    "    for a,b in pairs:\n",
    "        mask = (df['AccountNumber'].astype(str)==str(a)) & (df['CorrespondentAccountNumber'].astype(str)==str(b))\n",
    "        s = df[mask].groupby(df['ValueDate'].dt.date).size()\n",
    "        row = [1 if d.date() in s.index else 0 for d in dates]\n",
    "        mat.append(row)\n",
    "        labels.append(f'{a}->{b}')\n",
    "    return pd.DataFrame(mat, index=labels, columns=dates)\n",
    "\n",
    "pairs_for_heatmap = list(set(daily_pairs + weekly_pairs + monthly_pairs))[:VISUAL_CAP]\n",
    "if pairs_for_heatmap:\n",
    "    presence_df = build_presence_matrix(pairs_for_heatmap, df)\n",
    "    plt.figure(figsize=(14, max(3, 0.25*len(presence_df))))\n",
    "    plt.imshow(presence_df.values, aspect='auto', interpolation='nearest')\n",
    "    plt.yticks(range(len(presence_df.index)), presence_df.index)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Presence heatmap (rows: pairs, cols: days)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No pairs available for heatmap.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Network graph for recurring pairs (combine all 100% pairs)\n",
    "nodes = set()\n",
    "edges = []\n",
    "for dfp in [daily_100, weekly_100, monthly_100]:\n",
    "    for _, row in dfp.iterrows():\n",
    "        a = str(row['AccountNumber'])\n",
    "        b = str(row['CorrespondentAccountNumber'])\n",
    "        nodes.add(a); nodes.add(b)\n",
    "        edges.append((a,b))\n",
    "\n",
    "if edges and nx_available:\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(nodes)\n",
    "    G.add_edges_from(edges)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    nx.draw(G, pos, with_labels=True, arrows=True, node_size=500, font_size=8)\n",
    "    plt.title('Network of 100% recurring pairs (combined)')\n",
    "    plt.show()\n",
    "elif edges:\n",
    "    print('networkx not available in the environment; cannot draw network graph.')\n",
    "else:\n",
    "    print('No recurring edges to draw in network graph.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3866f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Bar chart: top recurring pairs by pct_weekly (or pct_daily if weekly not present)\n",
    "import numpy as np\n",
    "# compute a 'score' for ordering: mean of pct_daily, pct_weekly, pct_monthly\n",
    "final_df['score'] = final_df[['pct_daily','pct_weekly','pct_monthly']].mean(axis=1)\n",
    "topN = final_df[final_df['pct_daily']==100].copy().sort_values('score', ascending=False).head(VISUAL_CAP)\n",
    "if topN.empty:\n",
    "    topN = final_df[final_df['pct_weekly']==100].copy().sort_values('score', ascending=False).head(VISUAL_CAP)\n",
    "if topN.empty:\n",
    "    topN = final_df[final_df['pct_monthly']==100].copy().sort_values('score', ascending=False).head(VISUAL_CAP)\n",
    "\n",
    "if not topN.empty:\n",
    "    labels = topN['AccountNumber'].astype(str) + '->' + topN['CorrespondentAccountNumber'].astype(str)\n",
    "    vals = topN['score']\n",
    "    plt.figure(figsize=(10, max(4, 0.4*len(labels))))\n",
    "    plt.barh(range(len(vals)), vals)\n",
    "    plt.yticks(range(len(vals)), labels)\n",
    "    plt.xlabel('recurrence score (mean pct daily/weekly/monthly)')\n",
    "    plt.title('Top recurring pairs (100% in at least one bucket prioritized)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No top recurring pairs found for bar chart.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Amount-based recurrence/stability check\n",
    "# If 'Amount' column exists, compute cv (std/mean) per pair and show low-variance recurring pairs\n",
    "if 'Amount' in df.columns:\n",
    "    amt_stats = df.groupby(['AccountNumber','CorrespondentAccountNumber'])['Amount'].agg(['count','mean','std']).reset_index()\n",
    "    amt_stats['cv'] = amt_stats['std'] / amt_stats['mean'].replace({0: pd.NA})\n",
    "    # Merge with final_df to keep only 100% recurring pairs\n",
    "    merged = final_df.merge(amt_stats, on=['AccountNumber','CorrespondentAccountNumber'], how='left')\n",
    "    stable = merged[merged['cv'] <= 0.1].sort_values('cv').head(50)  # CV <= 0.1\n",
    "    print('Pairs with low CV (<=0.1):', len(stable))\n",
    "    if not stable.empty:\n",
    "        from IPython.display import display\n",
    "        display(stable[['AccountNumber','CorrespondentAccountNumber','count','mean','std','cv','pct_daily','pct_weekly','pct_monthly']])\n",
    "else:\n",
    "    print('No Amount column found; skipping amount-based stability check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e24169",
   "metadata": {},
   "source": [
    "### Final notes\n",
    "- The notebook filters only pairs with **100% recurrence** per your request. Visualizations are capped to avoid generating thousands of plots — you can change `VISUAL_CAP` at the top of the visualization section.  \n",
    "- Outputs saved: `/mnt/data/recurrence_results.xlsx` with sheets for all pairs and 100%-recurrence subsets.  \n",
    "- To re-run or adapt thresholds, modify the filters (e.g., `pct_weekly >= 80`) in the \"Filter 100% recurrence\" cell.\n",
    "\n",
    "You can download the notebook file and run it on your environment or in Colab (upload the transactions file to the same directory or to Colab's file system)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
